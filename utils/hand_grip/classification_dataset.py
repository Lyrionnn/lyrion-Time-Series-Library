import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import os

class HandGripClassificationDataset:
    """
    æ‰‹éƒ¨æŠ“æ¡æ—¶é—´åºåˆ—åˆ†ç±»æ•°æ®é›†ç±»
    æ”¯æŒå¤šç§åˆ†ç±»ä»»åŠ¡è®¾è®¡
    """
    
    def __init__(self, csv_data_dir):
        self.csv_data_dir = csv_data_dir
        self.scaler = StandardScaler()
        
    def create_multi_task_labels(self, file_path, features):
        """
        åˆ›å»ºå¤šä»»åŠ¡æ ‡ç­¾
        """
        labels = {}
        
        # ä»»åŠ¡1: å¥åº·çŠ¶æ€åˆ†ç±» (ä¸»è¦ä»»åŠ¡)
        if 'normal' in file_path:
            labels['health_status'] = 0  # æ­£å¸¸
        elif 'jzb' in file_path:
            labels['health_status'] = 1  # æ‚£è€…
        
        # ä»»åŠ¡2: æŠ“æ¡æ¬¡æ•°åˆ†ç±»
        grip_count = features.get('grip_count', 0)
        if grip_count <= 2:
            labels['grip_count_level'] = 0  # ä½é¢‘
        elif grip_count <= 5:
            labels['grip_count_level'] = 1  # ä¸­é¢‘
        else:
            labels['grip_count_level'] = 2  # é«˜é¢‘
        
        # ä»»åŠ¡3: è¿åŠ¨è´¨é‡è¯„ä¼°
        # åŸºäºå¹³æ»‘åº¦å’Œåè°ƒæ€§
        smoothness_avg = np.mean([features.get(f'{finger}_smoothness', 0) 
                                for finger in ['Thumb (WT)', 'Index (WI)', 'Middle (WM)', 'Ring (WR)', 'Pinky (WP)']])
        coordination = features.get('finger_coordination_mean', 0)
        
        # ç»¼åˆè¯„åˆ†
        quality_score = smoothness_avg * 0.6 + coordination * 0.4
        if quality_score < np.percentile([quality_score], 33):
            labels['motion_quality'] = 0  # å·®
        elif quality_score < np.percentile([quality_score], 67):
            labels['motion_quality'] = 1  # ä¸­ç­‰
        else:
            labels['motion_quality'] = 2  # å¥½
        
        # ä»»åŠ¡4: æŠ“æ¡é¢‘ç‡åˆ†ç±»
        grip_freq = features.get('grip_frequency', 0)
        if grip_freq < 0.5:
            labels['grip_frequency_level'] = 0  # ä½é¢‘
        elif grip_freq < 1.0:
            labels['grip_frequency_level'] = 1  # ä¸­é¢‘
        else:
            labels['grip_frequency_level'] = 2  # é«˜é¢‘
            
        return labels
    
    def create_sliding_windows(self, time_series, window_size=60, stride=30):
        """
        åˆ›å»ºæ»‘åŠ¨çª—å£ï¼Œç”¨äºåˆ†æå±€éƒ¨è¿åŠ¨æ¨¡å¼
        
        å‚æ•°:
        window_size: çª—å£å¤§å°ï¼ˆå¸§æ•°ï¼‰
        stride: æ»‘åŠ¨æ­¥é•¿
        """
        windows = []
        n_frames = len(time_series)
        
        for start in range(0, n_frames - window_size + 1, stride):
            end = start + window_size
            window = time_series[start:end]
            windows.append(window)
        
        return np.array(windows)
    
    def augment_time_series(self, time_series, augmentation_factor=3):
        """
        æ—¶é—´åºåˆ—æ•°æ®å¢å¼º
        """
        augmented_data = [time_series]  # åŸå§‹æ•°æ®
        
        for _ in range(augmentation_factor - 1):
            # 1. æ·»åŠ å™ªå£°
            noise_level = 0.02
            noisy_series = time_series + np.random.normal(0, noise_level, time_series.shape)
            
            # 2. æ—¶é—´æ‰­æ›²ï¼ˆè½»å¾®çš„æ—¶é—´ä¼¸ç¼©ï¼‰
            time_warp_factor = np.random.uniform(0.95, 1.05)
            original_length = len(time_series)
            new_length = int(original_length * time_warp_factor)
            
            if new_length > 0:
                indices = np.linspace(0, original_length-1, new_length)
                warped_series = np.array([np.interp(indices, range(original_length), time_series[:, i]) 
                                        for i in range(time_series.shape[1])]).T
                
                # è°ƒæ•´å›åŸå§‹é•¿åº¦
                if len(warped_series) != original_length:
                    indices_back = np.linspace(0, len(warped_series)-1, original_length)
                    warped_series = np.array([np.interp(indices_back, range(len(warped_series)), warped_series[:, i]) 
                                            for i in range(warped_series.shape[1])]).T
                
                augmented_data.append(warped_series)
            
            # 3. å¹…å€¼ç¼©æ”¾
            scale_factor = np.random.uniform(0.9, 1.1)
            scaled_series = time_series * scale_factor
            augmented_data.append(scaled_series)
        
        return augmented_data
    
    def save_to_ts_format(self, X_data, y_data, file_names, task_type, output_dir):
        """
        ä¿å­˜æ•°æ®ä¸º.tsæ ¼å¼æ–‡ä»¶
        """
        os.makedirs(output_dir, exist_ok=True)
        
        # æ–‡ä»¶å
        ts_filename = f"HandGrip_{task_type}.ts"
        mapping_filename = f"HandGrip_{task_type}_mapping.txt"
        
        ts_path = os.path.join(output_dir, ts_filename)
        mapping_path = os.path.join(output_dir, mapping_filename)
        
        # æ•°æ®é›†ä¿¡æ¯
        n_samples, series_length, n_dimensions = X_data.shape
        class_labels = np.unique(y_data)
        
        # å†™å…¥.tsæ–‡ä»¶
        with open(ts_path, 'w') as f:
            # å†™å…¥å…ƒæ•°æ®å¤´
            f.write(f"@problemName HandGrip_{task_type}\n")
            f.write(f"@timeStamps false\n")
            f.write(f"@missing false\n")
            f.write(f"@univariate false\n")
            f.write(f"@dimensions {n_dimensions}\n")
            f.write(f"@equalLength true\n")
            f.write(f"@seriesLength {series_length}\n")
            f.write(f"@classLabel true {' '.join(map(str, class_labels))}\n")
            f.write("@data\n")
            
            # å†™å…¥æ•°æ®è¡Œ
            for i in range(n_samples):
                # å°†æ¯ä¸ªæ—¶é—´æ­¥çš„æ‰€æœ‰ç»´åº¦å€¼æŒ‰é¡ºåºæ’åˆ—
                series_data = []
                for t in range(series_length):
                    series_data.extend([f"{val:.6f}" for val in X_data[i, t]])
                # å°†æ•´ä¸ªåºåˆ—è¿æ¥èµ·æ¥ï¼Œç„¶åæ·»åŠ æ ‡ç­¾
                line = ",".join(series_data) + f":{y_data[i]}\n"
                f.write(line)
        
        # å†™å…¥æ˜ å°„æ–‡ä»¶
        with open(mapping_path, 'w') as f:
            f.write(f"# {task_type} åˆ†ç±»ä»»åŠ¡çš„æ•°æ®è¡Œä¸åŸå§‹æ–‡ä»¶åæ˜ å°„å…³ç³»\n")
            f.write("# æ ¼å¼: è¡Œå· -> åŸå§‹æ–‡ä»¶å (æ ‡ç­¾)\n")
            f.write(f"# æ ‡ç­¾å«ä¹‰: {self.get_label_meaning(task_type)}\n")
            for i, (filename, label) in enumerate(zip(file_names, y_data)):
                f.write(f"{i+1} -> {filename} (æ ‡ç­¾: {label})\n")
        
        print(f"âœ… .tsæ–‡ä»¶å·²ä¿å­˜: {ts_path}")
        print(f"âœ… æ˜ å°„æ–‡ä»¶å·²ä¿å­˜: {mapping_path}")
        
        return ts_path, mapping_path
    
    def get_label_meaning(self, task_type):
        """è·å–æ ‡ç­¾å«ä¹‰è¯´æ˜"""
        meanings = {
            'health_status': '0=æ­£å¸¸äºº, 1=æ‚£è€…',
            'grip_count_level': '0=ä½é¢‘æŠ“æ¡(â‰¤2æ¬¡), 1=ä¸­é¢‘æŠ“æ¡(3-5æ¬¡), 2=é«˜é¢‘æŠ“æ¡(>5æ¬¡)',
            'motion_quality': '0=è¿åŠ¨è´¨é‡å·®, 1=è¿åŠ¨è´¨é‡ä¸­ç­‰, 2=è¿åŠ¨è´¨é‡å¥½',
            'grip_frequency_level': '0=ä½é¢‘ç‡(<0.5Hz), 1=ä¸­é¢‘ç‡(0.5-1Hz), 2=é«˜é¢‘ç‡(>1Hz)'
        }
        return meanings.get(task_type, 'æœªçŸ¥ä»»åŠ¡ç±»å‹')
    
    def prepare_classification_dataset(self, task_type='health_status', 
                                     use_sliding_window=True, 
                                     window_size=60,
                                     use_augmentation=True,
                                     save_to_ts=True,
                                     output_dir="../dataset/HandGrip_Enhanced/"):
        """
        å‡†å¤‡åˆ†ç±»æ•°æ®é›†
        
        å‚æ•°:
        task_type: åˆ†ç±»ä»»åŠ¡ç±»å‹ ('health_status', 'grip_count_level', 'motion_quality', 'grip_frequency_level')
        use_sliding_window: æ˜¯å¦ä½¿ç”¨æ»‘åŠ¨çª—å£
        window_size: çª—å£å¤§å°
        use_augmentation: æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼º
        """
        from feature_engineering import create_enhanced_time_series
        
        X_data = []
        y_data = []
        file_names = []
        
        # å¤„ç†normalç›®å½•
        normal_dir = os.path.join(self.csv_data_dir, 'normal')
        if os.path.exists(normal_dir):
            for file in os.listdir(normal_dir):
                if file.endswith('.csv'):
                    file_path = os.path.join(normal_dir, file)
                    try:
                        enhanced_ts, features = create_enhanced_time_series(file_path)
                        labels = self.create_multi_task_labels(file_path, features)
                        
                        if use_sliding_window and len(enhanced_ts) > window_size:
                            windows = self.create_sliding_windows(enhanced_ts, window_size)
                            for window in windows:
                                X_data.append(window)
                                y_data.append(labels[task_type])
                                file_names.append(file.replace('.csv', ''))
                        else:
                            X_data.append(enhanced_ts)
                            y_data.append(labels[task_type])
                            file_names.append(file.replace('.csv', ''))
                            
                        # æ•°æ®å¢å¼º
                        if use_augmentation:
                            augmented_series = self.augment_time_series(enhanced_ts)
                            for aug_ts in augmented_series[1:]:  # è·³è¿‡åŸå§‹æ•°æ®
                                if use_sliding_window and len(aug_ts) > window_size:
                                    windows = self.create_sliding_windows(aug_ts, window_size)
                                    for window in windows:
                                        X_data.append(window)
                                        y_data.append(labels[task_type])
                                        file_names.append(file.replace('.csv', '') + '_aug')
                                else:
                                    X_data.append(aug_ts)
                                    y_data.append(labels[task_type])
                                    file_names.append(file.replace('.csv', '') + '_aug')
                                    
                    except Exception as e:
                        print(f"å¤„ç†æ–‡ä»¶ {file} æ—¶å‡ºé”™: {e}")
        
        # å¤„ç†jzbç›®å½•
        jzb_dir = os.path.join(self.csv_data_dir, 'jzb')
        if os.path.exists(jzb_dir):
            for file in os.listdir(jzb_dir):
                if file.endswith('.csv'):
                    file_path = os.path.join(jzb_dir, file)
                    try:
                        enhanced_ts, features = create_enhanced_time_series(file_path)
                        labels = self.create_multi_task_labels(file_path, features)
                        
                        if use_sliding_window and len(enhanced_ts) > window_size:
                            windows = self.create_sliding_windows(enhanced_ts, window_size)
                            for window in windows:
                                X_data.append(window)
                                y_data.append(labels[task_type])
                                file_names.append(file.replace('.csv', ''))
                        else:
                            X_data.append(enhanced_ts)
                            y_data.append(labels[task_type])
                            file_names.append(file.replace('.csv', ''))
                            
                        # æ•°æ®å¢å¼º
                        if use_augmentation:
                            augmented_series = self.augment_time_series(enhanced_ts)
                            for aug_ts in augmented_series[1:]:  # è·³è¿‡åŸå§‹æ•°æ®
                                if use_sliding_window and len(aug_ts) > window_size:
                                    windows = self.create_sliding_windows(aug_ts, window_size)
                                    for window in windows:
                                        X_data.append(window)
                                        y_data.append(labels[task_type])
                                        file_names.append(file.replace('.csv', '') + '_aug')
                                else:
                                    X_data.append(aug_ts)
                                    y_data.append(labels[task_type])
                                    file_names.append(file.replace('.csv', '') + '_aug')
                                    
                    except Exception as e:
                        print(f"å¤„ç†æ–‡ä»¶ {file} æ—¶å‡ºé”™: {e}")
        
        # ç»Ÿä¸€é•¿åº¦å¤„ç†
        if X_data:
            max_length = max(len(x) for x in X_data)
            X_processed = []
            
            for x in X_data:
                if len(x) < max_length:
                    # ç”¨æœ€åä¸€ä¸ªå€¼å¡«å……
                    padding = np.tile(x[-1:], (max_length - len(x), 1))
                    x_padded = np.vstack([x, padding])
                else:
                    x_padded = x[:max_length]
                X_processed.append(x_padded)
            
            X_data = np.array(X_processed)
            y_data = np.array(y_data)
            
            print(f"æ•°æ®é›†å‡†å¤‡å®Œæˆ:")
            print(f"æ ·æœ¬æ•°é‡: {len(X_data)}")
            print(f"æ—¶é—´åºåˆ—é•¿åº¦: {X_data.shape[1]}")
            print(f"ç‰¹å¾ç»´åº¦: {X_data.shape[2]}")
            print(f"æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y_data)}")
            
            # ä¿å­˜ä¸º.tsæ–‡ä»¶
            if save_to_ts:
                self.save_to_ts_format(X_data, y_data, file_names, task_type, output_dir)
            
            return X_data, y_data, file_names
        else:
            print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®æ–‡ä»¶")
            return None, None, None

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæ•°æ®é›†
    dataset = HandGripClassificationDataset("./csv_data")
    
    print("=== ç”Ÿæˆå¤šä¸ªåˆ†ç±»ä»»åŠ¡çš„.tsæ•°æ®é›† ===")
    
    # 1. å¥åº·çŠ¶æ€åˆ†ç±»æ•°æ®é›†ï¼ˆä¸»ä»»åŠ¡ï¼‰
    print("\n1. å‡†å¤‡å¥åº·çŠ¶æ€åˆ†ç±»æ•°æ®é›†...")
    X1, y1, files1 = dataset.prepare_classification_dataset(
        task_type='health_status',
        use_sliding_window=False,  # å…ˆä¸ä½¿ç”¨æ»‘åŠ¨çª—å£
        use_augmentation=False,    # å…ˆä¸ä½¿ç”¨æ•°æ®å¢å¼º
        save_to_ts=True,
        output_dir="../dataset/HandGrip_Enhanced/"
    )
    
    # 2. æŠ“æ¡æ¬¡æ•°åˆ†çº§æ•°æ®é›†
    print("\n2. å‡†å¤‡æŠ“æ¡æ¬¡æ•°åˆ†çº§æ•°æ®é›†...")
    X2, y2, files2 = dataset.prepare_classification_dataset(
        task_type='grip_count_level',
        use_sliding_window=False,
        use_augmentation=False,
        save_to_ts=True,
        output_dir="../dataset/HandGrip_Enhanced/"
    )
    
    # 3. è¿åŠ¨è´¨é‡è¯„ä¼°æ•°æ®é›†
    print("\n3. å‡†å¤‡è¿åŠ¨è´¨é‡è¯„ä¼°æ•°æ®é›†...")
    X3, y3, files3 = dataset.prepare_classification_dataset(
        task_type='motion_quality',
        use_sliding_window=False,
        use_augmentation=False,
        save_to_ts=True,
        output_dir="../dataset/HandGrip_Enhanced/"
    )
    
    # 4. æŠ“æ¡é¢‘ç‡åˆ†ææ•°æ®é›†
    print("\n4. å‡†å¤‡æŠ“æ¡é¢‘ç‡åˆ†ææ•°æ®é›†...")
    X4, y4, files4 = dataset.prepare_classification_dataset(
        task_type='grip_frequency_level',
        use_sliding_window=False,
        use_augmentation=False,
        save_to_ts=True,
        output_dir="../dataset/HandGrip_Enhanced/"
    )
    
    print("\n=== æ•°æ®é›†ç”Ÿæˆå®Œæˆ ===")
    print("ç”Ÿæˆçš„.tsæ–‡ä»¶ä½ç½®:")
    print("ğŸ“ ../dataset/HandGrip_Enhanced/")
    print("   â”œâ”€â”€ HandGrip_health_status.ts          (å¥åº·çŠ¶æ€åˆ†ç±»)")
    print("   â”œâ”€â”€ HandGrip_grip_count_level.ts       (æŠ“æ¡æ¬¡æ•°åˆ†çº§)")
    print("   â”œâ”€â”€ HandGrip_motion_quality.ts         (è¿åŠ¨è´¨é‡è¯„ä¼°)")
    print("   â”œâ”€â”€ HandGrip_grip_frequency_level.ts   (æŠ“æ¡é¢‘ç‡åˆ†æ)")
    print("   â””â”€â”€ å¯¹åº”çš„_mapping.txtæ–‡ä»¶")
    
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("python run.py --task_name classification --is_training 1 \\")
    print("  --model TimesNet --data UEA \\")
    print("  --root_path ./dataset/HandGrip_Enhanced/ \\")
    print("  --model_id HandGrip_health_status")